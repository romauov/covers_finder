{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка и анализ данных\n",
    "\n",
    "Загружаем модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем сами данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_json('datasets/meta.json', lines=True)\n",
    "covers = pd.read_json('datasets/covers.json', lines=True)\n",
    "lyrics = pd.read_json('datasets/lyrics.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим данные в единый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72906 entries, 0 to 72905\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   track_id           72905 non-null  object \n",
      " 1   dttm               72905 non-null  float64\n",
      " 2   title              72905 non-null  object \n",
      " 3   language           22870 non-null  object \n",
      " 4   isrc               72566 non-null  object \n",
      " 5   genres             72905 non-null  object \n",
      " 6   duration           72905 non-null  float64\n",
      " 7   text               11414 non-null  object \n",
      " 8   original_track_id  5378 non-null   object \n",
      " 9   track_remake_type  72571 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df = meta.merge(lyrics, left_on = 'track_id', right_on = 'track_id', how='outer')\n",
    "df = df.merge(covers, left_on = 'track_id', right_on = 'track_id', how='outer')\n",
    "df.drop('lyricId', axis= 1 , inplace= True )\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим большое количество пропусков в некоторых колонках. К сожалению, это те данные, с которыми мы будем работать. Для построения и оценки алгоритма группирования нам необходимы размеченные данные с текстом, потому заполнять пропуски в этих колонках мы не можем, но можем заполнить пропуски в колонке language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72906 entries, 0 to 72905\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   track_id           72905 non-null  object \n",
      " 1   dttm               72905 non-null  float64\n",
      " 2   title              72905 non-null  object \n",
      " 3   language           72906 non-null  object \n",
      " 4   isrc               72566 non-null  object \n",
      " 5   genres             72905 non-null  object \n",
      " 6   duration           72905 non-null  float64\n",
      " 7   text               11414 non-null  object \n",
      " 8   original_track_id  5378 non-null   object \n",
      " 9   track_remake_type  72571 non-null  object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2 = df2[['language', 'original_track_id']].dropna() #Создаём временный датасет, где есть только размеченные данные, но не заполняем пропуски \n",
    "#в языке\n",
    "df['language'] = df['language'].fillna('Unknown')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовим данные обучения модели\n",
    "\n",
    "Избавимся от пропусков, оставим только размеченные данные. Проверим данные на дубликаты по столбцу track_id и избавимся от них, если надо. Колонка genres нам пока не понадобится, так что от неё тоже избавимся. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество дубликатов:  541\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   track_id           3000 non-null   object \n",
      " 1   dttm               3000 non-null   float64\n",
      " 2   title              3000 non-null   object \n",
      " 3   language           3000 non-null   object \n",
      " 4   isrc               3000 non-null   object \n",
      " 5   duration           3000 non-null   float64\n",
      " 6   text               3000 non-null   object \n",
      " 7   original_track_id  3000 non-null   object \n",
      " 8   track_remake_type  3000 non-null   object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 211.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data = data.dropna()\n",
    "data.drop('genres', axis= 1 , inplace= True )\n",
    "print(\"Количество дубликатов: \",data.duplicated(subset='track_id').sum())\n",
    "print()\n",
    "data = data.drop_duplicates(subset='track_id')\n",
    "#data = data.query('language == \"EN\"')\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сути, наша модель будет представлять собой алгоритм, который сможет искать в заданном датасете наиболее похожие тексты. Для этого будем использовать модуль nltk. \n",
    "\n",
    "Мы расчитаем расстояние нашего трека со всеми остальными в датасете. Группу треков будем составлять исходя из близости текстов треков. Те треки, которые ближе определённого значения, находятся в нашей группе и среди них есть каверы и оригинал (который мы будем считать по дате).\n",
    "\n",
    "По сути, обучение модели сводится к подбору оптимального порога.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Функция, рассчитывающая расстояние между двумя текстами\n",
    "def cosine_sim(text1, text2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n",
    "\n",
    "#Функция, собственно выполняющая расчёты\n",
    "def distantions(data_frame = data, my_text = '', tresh_hold = -1, column_name_ = 'text'):\n",
    "    #Функция принимает два параметра - датафрейм, с которым мы будем иметь дело и текст трека, с которым мы будем сравнивать всё остальное.\n",
    "    #По умолчанию, значение data_frame = data, но можно использовать любой датафрейм. Параметр column_name_ указывает название колонку\n",
    "    #с текстами песен. Можно также анализировать по названию, тогда надо указать соответствующую колонку\n",
    "    df_ = data_frame.copy()\n",
    "   \n",
    "    df_['sim'] = 0 #Создаём столбец, куда будем записывать расстояния нашего текста с остальными.\n",
    "    df_['sim'] = df_['sim'].astype(float)\n",
    "    text_1 = my_text\n",
    "    \n",
    "    #Перебираем все возможные тексты в датафрейме\n",
    "    for i in range(len(df_)):\n",
    "        try:\n",
    "            text_2 = df_.loc[i,column_name_]  \n",
    "            corpus = [text_1, text_2]\n",
    "            #Присваиваем i-той строке столбца dist значение, равное расстоянию нашего текста до его текста\n",
    "            df_.loc[i, 'sim'] = cosine_sim(text_1, text_2)\n",
    "            \n",
    "        except:\n",
    "            ...\n",
    "    #Возвращаем исходный датафрейм с новым столбцом\n",
    "    if tresh_hold == -1:\n",
    "        return df_\n",
    "    else:\n",
    "        df_ = df_.query('sim >= @tresh_hold')\n",
    "        return df_ \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь создадим функцию, которая будет выдавать нам метрику для каждого конкретного трека. В качестве параметров она будет принимать три значения:\n",
    "- df1 - датасет, в котором уже размечены расстояния от исходного трека до всех остальных\n",
    "- tid - Номер строки трека, с которым мы сравниваем в датасете, который мы передаём. \n",
    "- tresh_hold - пороговое сравнение. \n",
    "\n",
    "Это работает так: когда мы используем функцию, возвращающую схожесть разных текстов, мы считаем, что к нашей группе относятся тексты, которые схожи больше, чем на определённое значение. Эта функция высчитывает абсолютное значение ложноположительных и ложноотрицательных результатов.\n",
    "\n",
    "Это значит, она считает сколько треков, не относящейся к нашей группе, модель относит к ней при заданном пороге и наоборот, сколько треков относящихся к нашей группе, модель относит к группе.\n",
    "\n",
    "Напомню, что под группой мы подразумеваем треки, которые являются оригиналом и его каверами. В размеченных данных это те треки, у которых одинаковый original_track_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_metric(df1, tid, tresh_hold):\n",
    "    DF_METRIC = df1.copy()\n",
    "    TRAC_ID = DF_METRIC.loc[tid,'track_id']\n",
    "    otid =  DF_METRIC.loc[tid, 'original_track_id']\n",
    "    METRIC = len(DF_METRIC.query('original_track_id == @otid'))\n",
    "    false_positive = len(DF_METRIC.query('sim >= @tresh_hold & original_track_id != @otid'))  #Количество ложноположительных результатов\n",
    "    false_negative = len(DF_METRIC.query('sim < @tresh_hold & original_track_id == @otid')) # Количество ложноотрицательных результатов\n",
    "    false_positive_rel = false_positive / METRIC\n",
    "    false_negative_rel = false_negative / METRIC\n",
    "    true_positive = len(DF_METRIC.query('sim >= @tresh_hold & original_track_id == @otid'))\n",
    "    true_negative = len(DF_METRIC.query('sim < @tresh_hold & original_track_id != @otid')) \n",
    "    classic_precision = true_positive / (true_positive + false_positive)\n",
    "    classic_recall = true_positive / (true_positive + false_negative)\n",
    "    F1 = 2 * (classic_precision * classic_recall) / (classic_precision + classic_recall)\n",
    "    return false_positive, false_negative, false_positive_rel, false_negative_rel, classic_precision, classic_recall, F1, TRAC_ID\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно собственно расчитать оптимальный порог. Это и есть единственный параметр нашей модели. Для этого возьмём список разных порогов,\n",
    "рассчитаем метрики для каждого значения и сравним. Считать мы будем по всему тренировочному датасету, в качестве итогового результата будут СРЕДНИЕ значения ошибок. То есть, мы узнаем, сколько в среднем наша модель выдаёт ложных срабатываний.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresh_hold = [0, 0.5,0.6, 0.7, 0.75, 0.8, 0.9] #значения порогов\n",
    "LIST = [] #Создаём пустой список\n",
    "#Превращаем его в список пустых списков. Да, я пробовал LIST = [[]] * len(tresh_hold), но в таком случае дальнейшая процедура работает \n",
    "#некорректно, потому приходится именно так извращаться и делать это в цикле.\n",
    "for i in range(len(tresh_hold)):\n",
    "\n",
    "   LIST.append([])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4640c9b2c14643a63e957f0d78c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#В данном цикле считаем метрики для КАЖДОГО трека с КАЖДЫМ значением порога. Результат записываем в наш список списков. \n",
    "#Соответственно, в каждом подсписке будут результаты для всего датасета с соответствующим пороговым значением. \n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    result = distantions(data_frame = data, my_text = data.loc[i, 'text'], tresh_hold = -1)\n",
    "    for i2 in range(len(tresh_hold)):\n",
    "        cortege = find_metric(result, i, tresh_hold[i2])\n",
    "        \n",
    "        LIST[i2].append(cortege)\n",
    "        \n",
    "            \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treshhold</th>\n",
       "      <th>FP_abs</th>\n",
       "      <th>FN_abs</th>\n",
       "      <th>FP_rel</th>\n",
       "      <th>FN_rel</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2997.874000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2781.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.577333</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>1.331448</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>0.854366</td>\n",
       "      <td>0.990412</td>\n",
       "      <td>0.877218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.370667</td>\n",
       "      <td>0.264667</td>\n",
       "      <td>0.316758</td>\n",
       "      <td>0.015051</td>\n",
       "      <td>0.934367</td>\n",
       "      <td>0.984949</td>\n",
       "      <td>0.940366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.194667</td>\n",
       "      <td>0.382667</td>\n",
       "      <td>0.160568</td>\n",
       "      <td>0.021213</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>0.978787</td>\n",
       "      <td>0.954147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.148000</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.119756</td>\n",
       "      <td>0.026378</td>\n",
       "      <td>0.963735</td>\n",
       "      <td>0.973622</td>\n",
       "      <td>0.955039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.118667</td>\n",
       "      <td>0.548667</td>\n",
       "      <td>0.094023</td>\n",
       "      <td>0.030713</td>\n",
       "      <td>0.968270</td>\n",
       "      <td>0.969287</td>\n",
       "      <td>0.955073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.790667</td>\n",
       "      <td>0.059029</td>\n",
       "      <td>0.045477</td>\n",
       "      <td>0.975493</td>\n",
       "      <td>0.954523</td>\n",
       "      <td>0.947067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Treshhold       FP_abs    FN_abs       FP_rel    FN_rel  Precision  \\\n",
       "0       0.00  2997.874000  0.000000  2781.000000  0.000000   0.000709   \n",
       "1       0.50     1.577333  0.146667     1.331448  0.009588   0.854366   \n",
       "2       0.60     0.370667  0.264667     0.316758  0.015051   0.934367   \n",
       "3       0.70     0.194667  0.382667     0.160568  0.021213   0.957449   \n",
       "4       0.75     0.148000  0.464000     0.119756  0.026378   0.963735   \n",
       "5       0.80     0.118667  0.548667     0.094023  0.030713   0.968270   \n",
       "6       0.90     0.074000  0.790667     0.059029  0.045477   0.975493   \n",
       "\n",
       "     Recall        F1  \n",
       "0  1.000000  0.001412  \n",
       "1  0.990412  0.877218  \n",
       "2  0.984949  0.940366  \n",
       "3  0.978787  0.954147  \n",
       "4  0.973622  0.955039  \n",
       "5  0.969287  0.955073  \n",
       "6  0.954523  0.947067  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Теперь преобразуем списки в датафреймы и считаем средние ошибки.\n",
    "Metrics = []\n",
    "\n",
    "for i in range(len(tresh_hold)):\n",
    "   \n",
    "    DFERR = pd.DataFrame(LIST[i], columns = ['FP', 'FN', 'FPrel', 'FNrel','P', 'R', 'F1', 'ID'])\n",
    "\n",
    "    Metrics.append([tresh_hold[i], DFERR['FP'].mean(), DFERR['FN'].mean(), DFERR['FPrel'].mean(), DFERR['FNrel'].mean(), DFERR['P'].mean(), DFERR['R'].mean(), DFERR['F1'].mean()])\n",
    "    #print('Treshhold:', tresh_hold[i], 'FP:',  DFERR['FP'].mean(), 'FN:',   'FP_rel:', DFERR['FPrel'].mean(), 'FN_rel', DFERR['FNrel'].mean())\n",
    "\n",
    "Metrics = pd.DataFrame(Metrics, columns = ['Treshhold', 'FP_abs', 'FN_abs', 'FP_rel', 'FN_rel', 'Precision', 'Recall', 'F1'])\n",
    "Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы посчитали метрики для разных пороговых значений. В качестве метрики возьмём F1 метрику. Она считается таким образом: мы считаем метрику для каждого конкретного трека, то есть то, каким образом алгоритм определил кластер для конкретного трека, а затем считается усреднённое значение метрик. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию, которая выведет список всех \"похожих\" треков из заданного датасета, а также определит оригинал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_TRESHHOLD = 0.8\n",
    "CLEAR = ['track_id', 'title', 'text', 'year']\n",
    "\n",
    "#df_tracks -  \n",
    "def grouping_tracks(\n",
    "track_id, #Принимает на вход идентификатор трека (ОБЯЗАТЕЛЬНЫЙ ПАРАМЕТР)\n",
    "df_tracks = df, #Датафрейм, в котором будет проводиться поиск (ОБЯЗАТЕЛЬНЫЙ ПАРАМЕТР) \n",
    "method = 'text', #Метод, по которому будет проводиться поиск: \n",
    "                 #text - только по текстам песен\n",
    "                 #title - только по названиям песен\n",
    "                 #both - функция будет искать соотвествия как в названиях, так и в текстах. Треки с текстом будут выше в выдаче, они в любом\n",
    "                 #случае будут считаться более релевантными\n",
    "original = 'year', #Метод определения оригинала:\n",
    "                     #year \n",
    "tresh_hold_ = BEST_TRESHHOLD, #Параметр, который указывает какой порог использовать при поиске\n",
    "clear = True #Если True, выводит только несколько столбцов, иначе все\n",
    "):\n",
    "    df_tracks_ = df_tracks.copy()\n",
    "    if len(df_tracks.query('track_id == @track_id')) == 0:\n",
    "        return 'This music track was not found'\n",
    "    df_tracks_['year'] = df_tracks_['isrc'].str[5:7] #Получаем год регистрации трека\n",
    "\n",
    "    if method == 'text' or method == 'both':\n",
    "        txt = df_tracks.query('track_id == @track_id').reset_index(drop = True).loc[0, 'text']\n",
    "        result = distantions(data_frame = df_tracks_, my_text = txt, tresh_hold = tresh_hold_)\n",
    "    \n",
    "    if method == 'title' or method == 'both':\n",
    "        txt = df_tracks.query('track_id == @track_id').reset_index(drop = True).loc[0, 'title']\n",
    "        result2 = distantions(data_frame = df_tracks_, my_text = txt, tresh_hold = tresh_hold_, column_name_ = 'title')\n",
    "        if method == 'both':\n",
    "            result2['sim'] = result2['sim'].apply(lambda x: x - 2)\n",
    "            result = pd.concat([result, result2])\n",
    "            result = result.sort_values(by = 'sim', ascending = True)\n",
    "            result = result.drop_duplicates(subset='track_id')\n",
    "            result = result.sort_values(by = 'sim', ascending = False)\n",
    "        else:\n",
    "            result = result2\n",
    "    if original == 'year':\n",
    "        result['year'] = result['year'].fillna('5-')\n",
    "        result['year'] = result['year'].replace('5-', '9999')\n",
    "        result['year'] = result['year'].astype(int)\n",
    "        result['year'] = result['year'].apply(lambda x: x + 2000 if x <= 24 else x + 1900)\n",
    "        result_original = result.sort_values(by = 'year', ascending = True).head(1)\n",
    "    if clear:\n",
    "        return result_original[CLEAR], result[CLEAR]\n",
    "    else:\n",
    "        return result_original, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = grouping_tracks('deb9b9598176a0bab1212d430b10bd04', df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45447</th>\n",
       "      <td>deb9b9598176a0bab1212d430b10bd04</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               track_id                            title  \\\n",
       "45447  deb9b9598176a0bab1212d430b10bd04  Sweet Dreams (Are Made of This)   \n",
       "\n",
       "                                                    text  year  \n",
       "45447  Sweet dreams are made of this\\nWho am I to dis...  1983  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>8295168b2df271a91f9e4f5d6a7aad69</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17054</th>\n",
       "      <td>6a0060c234c43fcffd4b3ee28621af5a</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20426</th>\n",
       "      <td>08a52b88aa5ffca6b41b58c6d5ec7a52</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20427</th>\n",
       "      <td>08a52b88aa5ffca6b41b58c6d5ec7a52</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22278</th>\n",
       "      <td>8f36faa55a52681c41a6cfa1ff1176f0</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nSweet dreams ar...</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23161</th>\n",
       "      <td>97f3c02d03bcb3779c148bd060cc3483</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet, sweet dreams are made of this\\nWho am I...</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25084</th>\n",
       "      <td>f8fb3c76c159efb0033c3b48e0c2a045</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38375</th>\n",
       "      <td>07cf69ce6c50fe7846e2e90eb05b3aeb</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45447</th>\n",
       "      <td>deb9b9598176a0bab1212d430b10bd04</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45454</th>\n",
       "      <td>bf8b2ce531f3844f31a147ccca54151b</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46427</th>\n",
       "      <td>e1cf3c4ba848dee22984d5a767c83549</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52743</th>\n",
       "      <td>0d48e3683a1a0c0d3cec604fbf58fb35</td>\n",
       "      <td>Sweet Dreams (Are Made of This) [From \"X-Men: ...</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am i to dis...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52783</th>\n",
       "      <td>f66a59e4931cde981b70a3ae144fb7fb</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58593</th>\n",
       "      <td>749323aed3c585998d21db17eb3ceb3a</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69318</th>\n",
       "      <td>a7cf4d618804216039b91ecc8c50c024</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72814</th>\n",
       "      <td>4968f3f3cedda92f1063eba4764e083a</td>\n",
       "      <td>Sweet Dreams (Are Made of This)</td>\n",
       "      <td>Sweet dreams are made of this\\nWho am I to dis...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72879</th>\n",
       "      <td>94415e86e81da26ea31135d47825bab1</td>\n",
       "      <td>Sweet Dreams</td>\n",
       "      <td>Sweet dream\\nWho am I?\\nTravel the world\\nEver...</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               track_id  \\\n",
       "1564   8295168b2df271a91f9e4f5d6a7aad69   \n",
       "17054  6a0060c234c43fcffd4b3ee28621af5a   \n",
       "20426  08a52b88aa5ffca6b41b58c6d5ec7a52   \n",
       "20427  08a52b88aa5ffca6b41b58c6d5ec7a52   \n",
       "22278  8f36faa55a52681c41a6cfa1ff1176f0   \n",
       "23161  97f3c02d03bcb3779c148bd060cc3483   \n",
       "25084  f8fb3c76c159efb0033c3b48e0c2a045   \n",
       "38375  07cf69ce6c50fe7846e2e90eb05b3aeb   \n",
       "45447  deb9b9598176a0bab1212d430b10bd04   \n",
       "45454  bf8b2ce531f3844f31a147ccca54151b   \n",
       "46427  e1cf3c4ba848dee22984d5a767c83549   \n",
       "52743  0d48e3683a1a0c0d3cec604fbf58fb35   \n",
       "52783  f66a59e4931cde981b70a3ae144fb7fb   \n",
       "58593  749323aed3c585998d21db17eb3ceb3a   \n",
       "69318  a7cf4d618804216039b91ecc8c50c024   \n",
       "72814  4968f3f3cedda92f1063eba4764e083a   \n",
       "72879  94415e86e81da26ea31135d47825bab1   \n",
       "\n",
       "                                                   title  \\\n",
       "1564                     Sweet Dreams (Are Made of This)   \n",
       "17054                                       Sweet Dreams   \n",
       "20426                                       Sweet Dreams   \n",
       "20427                                       Sweet Dreams   \n",
       "22278                                       Sweet Dreams   \n",
       "23161                    Sweet Dreams (Are Made of This)   \n",
       "25084                                       Sweet Dreams   \n",
       "38375                                       Sweet Dreams   \n",
       "45447                    Sweet Dreams (Are Made of This)   \n",
       "45454                    Sweet Dreams (Are Made of This)   \n",
       "46427                                       Sweet Dreams   \n",
       "52743  Sweet Dreams (Are Made of This) [From \"X-Men: ...   \n",
       "52783                                       Sweet Dreams   \n",
       "58593                    Sweet Dreams (Are Made of This)   \n",
       "69318                    Sweet Dreams (Are Made of This)   \n",
       "72814                    Sweet Dreams (Are Made of This)   \n",
       "72879                                       Sweet Dreams   \n",
       "\n",
       "                                                    text  year  \n",
       "1564   Sweet dreams are made of this\\nWho am I to dis...  2021  \n",
       "17054  Sweet dreams are made of this\\nWho am I to dis...  2019  \n",
       "20426  Sweet dreams are made of this\\nWho am I to dis...  2019  \n",
       "20427  Sweet dreams are made of this\\nWho am I to dis...  2019  \n",
       "22278  Sweet dreams are made of this\\nSweet dreams ar...  2017  \n",
       "23161  Sweet, sweet dreams are made of this\\nWho am I...  1994  \n",
       "25084  Sweet dreams are made of this\\nWho am I to dis...  2021  \n",
       "38375  Sweet dreams are made of this\\nWho am I to dis...  2021  \n",
       "45447  Sweet dreams are made of this\\nWho am I to dis...  1983  \n",
       "45454  Sweet dreams are made of this\\nWho am I to dis...  2003  \n",
       "46427  Sweet dreams are made of this\\nWho am I to dis...  2009  \n",
       "52743  Sweet dreams are made of this\\nWho am i to dis...  2016  \n",
       "52783  Sweet dreams are made of this\\nWho am I to dis...  2016  \n",
       "58593  Sweet dreams are made of this\\nWho am I to dis...  2020  \n",
       "69318  Sweet dreams are made of this\\nWho am I to dis...  2019  \n",
       "72814  Sweet dreams are made of this\\nWho am I to dis...  2019  \n",
       "72879  Sweet dream\\nWho am I?\\nTravel the world\\nEver...  2019  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
